{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensorflow\n",
    "\n",
    "Tensorflow is one of the main libraries used for Deep Learning. Initialy, it was made for Tensor (nd-array) distributed computation and was extended with facilities for Machine Learning and Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.Tensor\n",
    "\n",
    "`Tensor` is the fundamental class of Tensorflow. A huge difference with NumPy is that `Tensor` are immutable objects, that is they can only be assigned once. They can represent operation tree on arrays or arrays themselves (actually an operation tree with only one node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)Metal device set to: Apple M1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 16:30:54.483824: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-09-10 16:30:54.483938: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[2,3],[4,5]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can not modify a `Tensor`, it is immutable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    t[1,0]=1\n",
    "except Exception as e:\n",
    "    print(f\"{type(e).__name__}: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ways to create `Tensor`s more easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0.]\n",
      " [0. 0.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.zeros((2, 2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "b = tf.ones((3, 3))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[7. 7.]\n",
      " [7. 7.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.fill((2, 2), 7.)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "d = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "e = tf.eye(4)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most simple operations that can be done on `ndarray` can be done on `Tensors`. Results of operations are `Tensor` themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[16 20 24]\n",
      " [28 32 36]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# element wise operations\n",
    "a = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "b = tf.constant([[7, 8, 9], [10, 11, 12]])\n",
    "c = a + b \n",
    "d = 2 * c  \n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 50]\n",
      " [122]], shape=(2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "\n",
    "a = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "b = tf.constant([[7], [8] , [9]])\n",
    "c = a @ b   \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the value of a `Tensor`in the from of an `ndarray` by the `numpy()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[ 50]\n",
      " [122]], shape=(2, 1), dtype=int32)\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 50]\n",
      " [122]]\n"
     ]
    }
   ],
   "source": [
    "print(type(c))\n",
    "print(c)\n",
    "d = c.numpy()\n",
    "print(type(d))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.Variables\n",
    "For now on, we have only seen stateless computation, also known as _functional programming_. To perform _imperative programming_, we need some mutable objects that can record changing data.\n",
    "\n",
    "Tensorflow provides `Variable` object for that purpose. An initial value must be provide to the variable constructor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for `Tensor`, you can get a `ndarray` copy of a `Variable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[2. 3.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(type(b))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of a `Variable` can be mofidified using `assign()` method, but its shape can not be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "a.assign([1, 2])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Cannot assign to variable Variable:0 due to variable shape (2,) and value shape (2, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a.assign([[1, 2], [3, 4]])\n",
    "except Exception as e:\n",
    "    print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read and modify a variable by the same operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([3., 5.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "print(a)\n",
    "a.assign_add([1.0, 2.0])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables will be later used as memories inside the computation engine used by Tensorflow (CPU/GPU/TPU), for example as parameters of a model to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient\n",
    "\n",
    "Operations which are recorded with `GradientTape` can be differentiate automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([48.999985], shape=(1,), dtype=float32)\n",
      "tf.Tensor([-13.999998], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([2.0])\n",
    "a = tf.constant([3.0])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    fx = (3*a-x)**2\n",
    "\n",
    "# The first argument is the last tensor to derivate\n",
    "# The second argument is a variable (or a list of variables) on which to perform the derivation \n",
    "d_fx_d_x = tape.gradient(fx,x)\n",
    "\n",
    "print(fx)\n",
    "print(d_fx_d_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: minimizing a function by a gradient descent\n",
    "\n",
    "Let's try to minimize $(3a-w)^2$ over $w$ where $a$ is a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: f([2.])=[48.999985]\n",
      "Step 1: f([3.3999999])=[31.359993]\n",
      "Step 2: f([4.5199995])=[20.070396]\n",
      "Step 3: f([5.4159994])=[12.8450575]\n",
      "Step 4: f([6.1327996])=[8.220837]\n",
      "Step 5: f([6.7062397])=[5.261336]\n",
      "Step 6: f([7.164992])=[3.367254]\n",
      "Step 7: f([7.5319934])=[2.1550431]\n",
      "Step 8: f([7.825595])=[1.379227]\n",
      "Step 9: f([8.060476])=[0.8827048]\n",
      "Step 10: f([8.248381])=[0.5649316]\n",
      "Step 11: f([8.398705])=[0.36155617]\n",
      "Step 12: f([8.518964])=[0.2313958]\n",
      "Step 13: f([8.615171])=[0.14809303]\n",
      "Step 14: f([8.692137])=[0.09477977]\n",
      "Step 15: f([8.75371])=[0.06065886]\n",
      "Step 16: f([8.802968])=[0.0388216]\n",
      "Step 17: f([8.842375])=[0.0248457]\n",
      "Step 18: f([8.873899])=[0.01590135]\n",
      "Step 19: f([8.899119])=[0.0101769]\n",
      "Step 20: f([8.919295])=[0.00651325]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([2.0])\n",
    "a = tf.constant([3.0])\n",
    "\n",
    "nstep = 20\n",
    "lr = 1e-1\n",
    "\n",
    "def myfunc(w,a):\n",
    "    return (3*a-w)**2\n",
    "\n",
    "for i in range(nstep):\n",
    "    \n",
    "    # Computing the function meanwhile recording a gradient tape\n",
    "    with tf.GradientTape() as tape:\n",
    "        f = myfunc(w,a)\n",
    "    print(\"Step %d: f(%s)=%s\" % (i, w.numpy(), f.numpy()))\n",
    "    \n",
    "    # Computing the gradient trough the tape \n",
    "    d_f_d_w = tape.gradient(f,w)\n",
    "    # Doing a gradient descent step\n",
    "    w.assign_add(-lr*d_f_d_w)\n",
    "\n",
    "f = myfunc(w,a)\n",
    "print(\"Step %d: f(%s)=%s\" % (nstep, w.numpy(), f.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple variables\n",
    "\n",
    "Here is a code to minimize $(<w,x>+b)^2$ over $w$ and $b$ where $w$ and $x$ are vectors of size 2, $b$ a scalar. $x$ is given by the user (no need to be interactive).\n",
    "\n",
    "To do the scalar product of $x$ and $y$ you can use:\n",
    "\n",
    "`tf.reduce_sum(tf.multiply(x,y))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: f([2. 3.],[3.])=[64.]\n",
      "Step 1: f([0.39999998 1.4       ],[1.4])=[10.239998]\n",
      "Step 2: f([-0.23999995  0.76000005],[0.76000005])=[1.6384003]\n",
      "Step 3: f([-0.49599996  0.50400007],[0.50400007])=[0.26214418]\n",
      "Step 4: f([-0.5984      0.40160003],[0.40160003])=[0.04194307]\n",
      "Step 5: f([-0.63936     0.36064002],[0.36064002])=[0.00671089]\n",
      "Step 6: f([-0.655744  0.344256],[0.344256])=[0.00107374]\n",
      "Step 7: f([-0.6622976   0.33770242],[0.33770242])=[0.0001718]\n",
      "Step 8: f([-0.6649191   0.33508098],[0.33508098])=[2.7487846e-05]\n",
      "Step 9: f([-0.66596764  0.33403242],[0.33403242])=[4.398207e-06]\n",
      "Step 10: f([-0.6663871   0.33361298],[0.33361298])=[7.0371317e-07]\n",
      "Step 11: f([-0.66655487  0.3334452 ],[0.3334452])=[1.1257001e-07]\n",
      "Step 12: f([-0.666622    0.33337808],[0.33337808])=[1.8001609e-08]\n",
      "Step 13: f([-0.6666488   0.33335125],[0.33335125])=[2.8840987e-09]\n",
      "Step 14: f([-0.66665953  0.33334053],[0.33334053])=[4.6299337e-10]\n",
      "Step 15: f([-0.6666638   0.33333623],[0.33333623])=[7.4695965e-11]\n",
      "Step 16: f([-0.66666555  0.3333345 ],[0.3333345])=[1.1951355e-11]\n",
      "Step 17: f([-0.66666627  0.33333382],[0.33333382])=[1.879389e-12]\n",
      "Step 18: f([-0.66666657  0.33333355],[0.33333355])=[2.8777005e-13]\n",
      "Step 19: f([-0.6666667   0.33333343],[0.33333343])=[3.1974437e-14]\n",
      "Step 20: f([-0.66666675  0.3333334 ],[0.3333334])=[3.5527133e-15]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([2.0, 3.0])\n",
    "b = tf.Variable([3.0])\n",
    "x = tf.constant([1.0, 1.0])\n",
    "\n",
    "nstep = 20\n",
    "lr = 1e-1\n",
    "\n",
    "def myfunc(w,b,x):\n",
    "    return (tf.reduce_sum(tf.multiply(w, x))+b)**2\n",
    "\n",
    "for i in range(nstep):\n",
    "    \n",
    "    # Computing the function meanwhile recording a gradient tape\n",
    "    with tf.GradientTape() as tape:\n",
    "        f = myfunc(w,b,x)\n",
    "    print(\"Step %d: f(%s,%s)=%s\" % (i, w.numpy(), b.numpy(), f.numpy()))\n",
    "    \n",
    "    # Computing the gradient trough the tape over all the variables \n",
    "    d_f_d_w, d_f_d_b = tape.gradient(f,[w,b])\n",
    "    # Doing a gradient descent step over all the variables\n",
    "    w.assign_add(-lr*d_f_d_w)\n",
    "    b.assign_add(-lr*d_f_d_b)\n",
    "\n",
    "f = myfunc(w,b,x)\n",
    "print(\"Step %d: f(%s,%s)=%s\" % (nstep, w.numpy(), b.numpy(), f.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.Function\n",
    "\n",
    "For now, our code was running into _eager_ mode which means that every single operation is read by the CPU before sent to the accelerator (such as the GPU) and the result return back to the CPU.\n",
    "\n",
    "In order to increase the performance (i.e. running a full bunch of code in the accelerate hardware without exchange with the CPU), the code must be representable into a _graph_ of operations (also called, Abstract Syntax Tree or AST) and then compiled specificaly for the GPU.\n",
    "\n",
    "`Tensorflow` builds automatically this _graph_ trough `tf.function` decorator which should be place before a function definition. This is the _autograph_ feature of the framework.\n",
    "The first time a function is called, each python/tensorflow instruction is read and registers into a graph.\n",
    "The graph is then compile for the accelerator.\n",
    "The next time the function is called, it is not anymore the python code which is executed but the accelerator code.\n",
    "\n",
    "In the next example, look at the `print` that you only see once.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphing foo\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 16:30:54.702663: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-10 16:30:54.703070: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-09-10 16:30:54.703193: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def foo(x):\n",
    "    print(\"Graphing foo\")\n",
    "    return tf.multiply(tf.constant([2]),x)\n",
    "\n",
    "print(foo(1))\n",
    "print(foo(1))\n",
    "print(foo(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our optimized code. Please note that `tf.Variable` should be created outside of a `tf.Function` or the _autograph_ will failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: f([2. 3.],[3.])=[64.]\n",
      "Step 1: f([0.39999998 1.4       ],[1.4])=[10.239999]\n",
      "Step 2: f([-0.23999995  0.76000005],[0.76000005])=[1.6384006]\n",
      "Step 3: f([-0.49599996  0.50400007],[0.50400007])=[0.2621442]\n",
      "Step 4: f([-0.5984      0.40160003],[0.40160003])=[0.04194307]\n",
      "Step 5: f([-0.63936     0.36064002],[0.36064002])=[0.00671089]\n",
      "Step 6: f([-0.655744  0.344256],[0.344256])=[0.00107374]\n",
      "Step 7: f([-0.6622976   0.33770242],[0.33770242])=[0.0001718]\n",
      "Step 8: f([-0.6649191   0.33508098],[0.33508098])=[2.7487835e-05]\n",
      "Step 9: f([-0.66596764  0.33403242],[0.33403242])=[4.3982036e-06]\n",
      "Step 10: f([-0.6663871   0.33361298],[0.33361298])=[7.0371254e-07]\n",
      "Step 11: f([-0.66655487  0.3334452 ],[0.3334452])=[1.1257001e-07]\n",
      "Step 12: f([-0.666622    0.33337808],[0.33337808])=[1.8001604e-08]\n",
      "Step 13: f([-0.6666488   0.33335125],[0.33335125])=[2.8840965e-09]\n",
      "Step 14: f([-0.66665953  0.33334053],[0.33334053])=[4.629932e-10]\n",
      "Step 15: f([-0.6666638   0.33333623],[0.33333623])=[7.4695805e-11]\n",
      "Step 16: f([-0.66666555  0.3333345 ],[0.3333345])=[1.1951329e-11]\n",
      "Step 17: f([-0.66666627  0.33333382],[0.33333382])=[1.8793855e-12]\n",
      "Step 18: f([-0.66666657  0.33333355],[0.33333355])=[2.877698e-13]\n",
      "Step 19: f([-0.6666667   0.33333343],[0.33333343])=[3.1974423e-14]\n",
      "Step 20: f([-0.66666675  0.3333334 ],[0.3333334])=[3.5527137e-15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 16:30:54.742149: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-10 16:30:54.751920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-10 16:30:54.807647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([2.0, 3.0])\n",
    "b = tf.Variable([3.0])\n",
    "x = tf.constant([1.0, 1.0])\n",
    "\n",
    "nstep = 20\n",
    "lr = 1e-1\n",
    "\n",
    "@tf.function\n",
    "def myfunc(w,b,x):\n",
    "    return (tf.reduce_sum(tf.multiply(w, x))+b)**2\n",
    "\n",
    "for i in range(nstep):\n",
    "    \n",
    "    # Computing the function meanwhile recording a gradient tape\n",
    "    with tf.GradientTape() as tape:\n",
    "        f = myfunc(w,b,x)\n",
    "    print(\"Step %d: f(%s,%s)=%s\" % (i, w.numpy(), b.numpy(), f.numpy()))\n",
    "    \n",
    "    # Computing the gradient trough the tape over all the variables \n",
    "    d_f_d_w, d_f_d_b = tape.gradient(f,[w,b])\n",
    "    # Doing a gradient descent step over all the variables\n",
    "    w.assign_add(-lr*d_f_d_w)\n",
    "    b.assign_add(-lr*d_f_d_b)\n",
    "\n",
    "f = myfunc(w,b,x)\n",
    "print(\"Step %d: f(%s,%s)=%s\" % (nstep, w.numpy(), b.numpy(), f.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.Module\n",
    "\n",
    "In order to help building more complex functions / models, `Tensorflow` provides a generic class pattern `tf.Module` to embed a model. Variables must be put into the `__init__` constructor of the class, and the actual computation or forward pass into the `__call__` methods.\n",
    "\n",
    "It provides tools such as getting all variables of a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable variables: (<tf.Variable 'b:0' shape=(1,) dtype=float32, numpy=array([3.], dtype=float32)>, <tf.Variable 'w:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>)\n",
      "all variables: (<tf.Variable 'b:0' shape=(1,) dtype=float32, numpy=array([3.], dtype=float32)>, <tf.Variable 'dummy:0' shape=() dtype=float32, numpy=4.0>, <tf.Variable 'w:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 16:30:54.820601: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "class MyModule(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.w = tf.Variable([1.0, 2.0], name='w')\n",
    "        self.b = tf.Variable([3.0], name='b')\n",
    "        # Dummy non trainable variable\n",
    "        self.dummy = tf.Variable(4.0, trainable=False, name='dummy')\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self,x):\n",
    "        return (tf.reduce_sum(tf.multiply(self.w, x))+self.b)**2\n",
    "\n",
    "aModule = MyModule()\n",
    "# All trainable variables\n",
    "print(\"trainable variables:\", aModule.trainable_variables)\n",
    "# Every variable\n",
    "print(\"all variables:\", aModule.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping it all\n",
    "\n",
    "Here is a simple code to optimize a module with an unkown number of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0:\n",
      "\tf=[36.]\n",
      "\tb:0=[3.]\n",
      "\tw:0=[1. 2.]\n",
      "Step 1:\n",
      "\tf=[5.76]\n",
      "\tb:0=[1.8000001]\n",
      "\tw:0=[-0.19999993  0.8000001 ]\n",
      "Step 2:\n",
      "\tf=[0.9216003]\n",
      "\tb:0=[1.32]\n",
      "\tw:0=[-0.67999995  0.32000008]\n",
      "Step 3:\n",
      "\tf=[0.1474561]\n",
      "\tb:0=[1.128]\n",
      "\tw:0=[-0.872       0.12800007]\n",
      "Step 4:\n",
      "\tf=[0.02359299]\n",
      "\tb:0=[1.0512]\n",
      "\tw:0=[-0.94879997  0.05120005]\n",
      "Step 5:\n",
      "\tf=[0.00377489]\n",
      "\tb:0=[1.02048]\n",
      "\tw:0=[-0.97951996  0.02048002]\n",
      "Step 6:\n",
      "\tf=[0.00060398]\n",
      "\tb:0=[1.0081921]\n",
      "\tw:0=[-0.991808  0.008192]\n",
      "Step 7:\n",
      "\tf=[9.663589e-05]\n",
      "\tb:0=[1.0032768]\n",
      "\tw:0=[-0.99672323  0.00327679]\n",
      "Step 8:\n",
      "\tf=[1.5461555e-05]\n",
      "\tb:0=[1.0013107]\n",
      "\tw:0=[-0.9986893   0.00131072]\n",
      "Step 9:\n",
      "\tf=[2.4738488e-06]\n",
      "\tb:0=[1.0005243]\n",
      "\tw:0=[-9.994757e-01  5.242932e-04]\n",
      "Step 10:\n",
      "\tf=[3.958008e-07]\n",
      "\tb:0=[1.0002097]\n",
      "\tw:0=[-9.9979031e-01  2.0972377e-04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 16:30:54.854929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-10 16:30:54.863908: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11:\n",
      "\tf=[6.329813e-08]\n",
      "\tb:0=[1.0000838]\n",
      "\tw:0=[-9.9991614e-01  8.3898325e-05]\n",
      "Step 12:\n",
      "\tf=[1.0122903e-08]\n",
      "\tb:0=[1.0000335]\n",
      "\tw:0=[-9.9996644e-01  3.3580083e-05]\n",
      "Step 13:\n",
      "\tf=[1.6187052e-09]\n",
      "\tb:0=[1.0000134]\n",
      "\tw:0=[-9.99986589e-01  1.34575475e-05]\n",
      "Step 14:\n",
      "\tf=[2.5707791e-10]\n",
      "\tb:0=[1.0000052]\n",
      "\tw:0=[-9.9999464e-01  5.4109159e-06]\n",
      "Step 15:\n",
      "\tf=[4.067502e-11]\n",
      "\tb:0=[1.000002]\n",
      "\tw:0=[-9.9999785e-01  2.2041856e-06]\n",
      "Step 16:\n",
      "\tf=[6.5689676e-12]\n",
      "\tb:0=[1.0000007]\n",
      "\tw:0=[-9.999991e-01  9.286450e-07]\n",
      "Step 17:\n",
      "\tf=[1.0267343e-12]\n",
      "\tb:0=[1.0000002]\n",
      "\tw:0=[-9.9999964e-01  4.1604477e-07]\n",
      "Step 18:\n",
      "\tf=[1.7408297e-13]\n",
      "\tb:0=[1.]\n",
      "\tw:0=[-9.9999982e-01  2.1338893e-07]\n",
      "Step 19:\n",
      "\tf=[3.1974423e-14]\n",
      "\tb:0=[0.99999994]\n",
      "\tw:0=[-9.9999988e-01  1.2994238e-07]\n",
      "Step 20:\n",
      "\tf=[3.5527137e-15]\n",
      "\tb:0=[0.9999999]\n",
      "\tw:0=[-9.9999994e-01  9.4179583e-08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 16:30:54.923747: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "class MyModule(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.w = tf.Variable([1.0, 2.0], name='w')\n",
    "        self.b = tf.Variable([3.0], name='b')\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self,x):\n",
    "        return (tf.reduce_sum(tf.multiply(self.w, x))+self.b)**2\n",
    "\n",
    "aModule = MyModule()\n",
    "x = tf.constant([1.0, 1.0])\n",
    "\n",
    "nstep = 20\n",
    "lr = 1e-1\n",
    "for i in range(nstep):\n",
    "    \n",
    "    # Computing the function meanwhile recording a gradient tape\n",
    "    with tf.GradientTape() as tape:\n",
    "        f = aModule(x)\n",
    "    print(\"Step %d:\\n\\tf=%s\" % (i, f.numpy()))\n",
    "    for aVar in aModule.trainable_variables:\n",
    "        print('\\t%s=%s'%(aVar.name,aVar.numpy()))\n",
    "    \n",
    "    # Computing the gradient trough the tape over all the variables \n",
    "    grads = tape.gradient(f,aModule.trainable_variables)\n",
    "\n",
    "    # Doing a gradient descent step over all the variables\n",
    "    for aVariable,aGrad  in zip(aModule.trainable_variables, grads):\n",
    "        aVariable.assign_add(-lr*aGrad)\n",
    "\n",
    "f = aModule(x)\n",
    "print(\"Step %d:\\n\\tf=%s\" % (nstep, f.numpy()))\n",
    "for aVar in aModule.trainable_variables:\n",
    "    print('\\t%s=%s'%(aVar.name,aVar.numpy()))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
